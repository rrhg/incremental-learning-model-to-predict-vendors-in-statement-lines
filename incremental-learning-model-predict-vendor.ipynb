{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfbbd164-a33a-4b5d-92ee-a9062cf48320",
   "metadata": {},
   "source": [
    "Experimenting with river library:\n",
    "- create an incremental learning model\n",
    "- data is 616 tuples of (bank_statement_line, vendor)\n",
    "- split data\n",
    "- train one at a time: model.learn_one(sentence,label)\n",
    "- predict one from a bank_statement_line aka sentence\n",
    "- save & load model every 100 items to simulate real usage\n",
    "- see real predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b27ec5-53d2-4b1a-bdb2-633535f0d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import random\n",
    "from pprint import pprint\n",
    "import river\n",
    "from river.naive_bayes import MultinomialNB\n",
    "from river.feature_extraction import BagOfWords,TFIDF\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19935baa-512a-45d2-ab71-5672468b2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(river)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2903cd9b-570c-4793-b29c-d8fce4b2b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f3f095-b700-402f-a2ce-365df6bbb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data( d ):  # remove 10 items(test_data) from the last ~200 items (only test last 2 months)\n",
    "    test = []\n",
    "    indexes = random.sample( range(  400, len(d)-11   ), 10) # get 10 random indexes between 400 & 600...\n",
    "    # test only on the last 2 months(data was collected from 01/2021 to 06/2021) Every month have roughly 100 items. Total items ~= 616\n",
    "    print('data lenght == ',len(d))\n",
    "    print('random indexes used for test data ==>', indexes)\n",
    "    for i in indexes:\n",
    "        r = d.pop(i)\n",
    "        test.append(r)\n",
    "    return d, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c7d519-598e-48e1-8e7e-ce3459745c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m):\n",
    "    with open('saved_model.pkl', 'wb') as f:\n",
    "        pickle.dump(m, f)\n",
    "    print('==> model was saved')\n",
    "\n",
    "def load_model():\n",
    "    with open('saved_model.pkl', 'rb') as f:\n",
    "        m = pickle.load(f)\n",
    "    print('==> model was loaded')    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "291de2d8-eb53-4e58-8514-047211c3e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data lenght ==  616\n",
      "random indexes used for test data ==> [567, 591, 492, 450, 519, 563, 576, 530, 460, 420]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('model-data.csv')\n",
    "d = list( df.to_records(index=False) ) # river accepts a list of tuples\n",
    "data, test_data = split_data(d)\n",
    "#print(data[:5])\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88dee51-04c0-43b3-8a67-d26a0d7fc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = river.compose.Pipeline(\n",
    "    ('vectorizer',BagOfWords(lowercase=True)), #convert text(feature) from string to a dict\n",
    "    ('nb',MultinomialNB())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e69f13-8c8b-473e-98b4-079a1c9c386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_nb # visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6cfc906-530d-40c5-9285-dec53c7f9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_nb.steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe108089-7e9f-4a27-92cf-233360a9ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental training + saving & reloading model every 100 items bc thats how is going to be used\n",
      "\n",
      "==> model was saved\n",
      "amount of classes after 100 items ==  34\n",
      "model   metric   after  100 items ==> Accuracy: 60.40%\n",
      "==> model was loaded\n",
      "==> model was saved\n",
      "amount of classes after 200 items ==  54\n",
      "model   metric   after  200 items ==> Accuracy: 63.68%\n",
      "==> model was loaded\n",
      "==> model was saved\n",
      "amount of classes after 300 items ==  63\n",
      "model   metric   after  300 items ==> Accuracy: 68.77%\n",
      "==> model was loaded\n",
      "==> model was saved\n",
      "amount of classes after 400 items ==  78\n",
      "model   metric   after  400 items ==> Accuracy: 71.07%\n",
      "==> model was loaded\n",
      "==> model was saved\n",
      "amount of classes after 500 items ==  89\n",
      "model   metric   after  500 items ==> Accuracy: 71.66%\n",
      "==> model was loaded\n",
      "==> model was saved\n",
      "amount of classes after 600 items ==  102\n",
      "model   metric   after  600 items ==> Accuracy: 70.38%\n",
      "==> model was loaded\n",
      "==> model was saved\n"
     ]
    }
   ],
   "source": [
    "print('Incremental training + saving & reloading model every 100 items bc thats how is going to be used'); print()\n",
    "metric = river.metrics.Accuracy()\n",
    "save_interval = 100\n",
    "load = False\n",
    "\n",
    "for i, (sentence,label) in enumerate(data):\n",
    "    if load == True:\n",
    "        model = load_model()\n",
    "        load = False\n",
    "    pred_before = model.predict_one(sentence)\n",
    "    metric = metric.update(label, pred_before)\n",
    "    model = model.learn_one(sentence,label)\n",
    "    if i == save_interval:\n",
    "        save_model(model)\n",
    "        load = True\n",
    "        print('amount of classes after '+str(save_interval)+' items == ', len(model.predict_proba_one(sentence))  )\n",
    "        print('model   metric   after  '+str(save_interval)+' items ==> ' + str(metric))\n",
    "        del model # sanity ck\n",
    "        save_interval += 100\n",
    "\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecfc76d-0c17-432e-862f-b4bfa3fe45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Predictions of \"model\" with test_data'); print()\n",
    "# classes = model.predict_proba_one(sentence)\n",
    "# for sentence,label in test_data:\n",
    "#     p = model.predict_one( sentence )\n",
    "#     print('label in classes before == ', label in classes)\n",
    "#     print('Prediction, Label = '+p+', '+label)\n",
    "#     if p != label:\n",
    "#         print('WRONG!!! Sentence was: ', sentence)\n",
    "        \n",
    "#     model = model.learn_one(sentence,label)\n",
    "#     classes = model.predict_proba_one(sentence)\n",
    "#     print('label in classes after == ', label in classes)\n",
    "#     print('===================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0a6ec5-07c1-46ea-9999-9f60fef1d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Predictions of \"reloaded model\" with test_data'); print()\n",
    "# model_2 = load_model()\n",
    "# for sentence,label in test_data:\n",
    "#     p = model_2.predict_one( sentence )\n",
    "#     print('Prediction, Label = '+p+', '+label)\n",
    "#     if p != label:\n",
    "#         print('Sentence was: ', sentence)\n",
    "#         #print(pipe_nb.predict_proba_one(sentence))\n",
    "#         print('=========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7a79ceb-585a-44c6-a1ff-64de386c3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Predictions of \"untrained model\" with test_data'); print()\n",
    "\n",
    "# untrained_model = river.compose.Pipeline(\n",
    "#     ('vectorizer',BagOfWords(lowercase=True)), #convert text(feature) from string to a dict\n",
    "#     ('nb',MultinomialNB())\n",
    "# )\n",
    "\n",
    "# for sentence,label in test_data:\n",
    "#     p = untrained_model.predict_one( sentence )\n",
    "#     print('Prediction, Label = ', p, label)\n",
    "#     if p != label:\n",
    "#         print('Sentence was: ', sentence)\n",
    "#         #print(pipe_nb.predict_proba_one(sentence))\n",
    "#         print('=========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a67dbd59-9bee-45a2-b4a8-0413fe70fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure about *removing numbers* to improve accuracy\n",
    "# bc some labels iclude a number from the lime\n",
    "# data_without_numbers = []\n",
    "#for d in data:\n",
    "#    print('original => ', d[0])\n",
    "#    sentence = re.sub(r\"[0-9]+\",\"\", d[0])\n",
    "#    print('corrected => ' sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36cb3910-3d20-44bb-a9f7-f50fa2dce961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem w TextBlob ==> some corrections make it worse \n",
    "#from textblob import TextBlob\n",
    "#corrected_data = []\n",
    "#for d in data:\n",
    "#    print('original => ', d[0])\n",
    "#    sentence = TextBlob(d[0]).correct()\n",
    "#    print('corrected => ', sentence)\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ade61-ac75-48cf-8ba9-451c18238b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
